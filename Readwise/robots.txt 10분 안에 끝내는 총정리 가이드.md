# robots.txt 10분 안에 끝내는 총정리 가이드

![rw-book-cover](https://seo.tbwakorea.com/wp-content/uploads/2022/01/10분-안에-끝내는-robots.txt-총정리-가이드-TBWA-데이터랩.png)

## Metadata
- Author: [[Yoobin Hwang]]
- Full Title: robots.txt 10분 안에 끝내는 총정리 가이드
- Category: #articles
- Document Tags: [[https]] [[robots.txt]] 
- Summary: The text is a guide on robots.txt, comparing it to road signs for search engine crawlers. It explains the purpose of robots.txt, how to write it correctly, and where to upload it on a website for effective SEO. The guide emphasizes the importance of properly setting up robots.txt to prevent server overload and improve search engine optimization.
- URL: https://seo.tbwakorea.com/blog/robots-txt-complete-guide/

## Highlights
- 가장 기본적인 형식인 **모든 또는 특정 크롤러의 특정 폴더 이하 제한 문법** ([View Highlight](https://read.readwise.io/read/01hv0jf9n5rvft6gjzx8r2s7b6))
- robots.txt를 구성하는 요소는 크게 네 가지가 있습니다. 각각의 구성 요소를 모두 포함할 필요는 없지만 “User-agent”는 반드시 포함되어야 합니다.
  1. **User-agent**: robots.txt 에서 지정하는 크롤링 규칙이 적용되어야 할 크롤러를 지정합니다.
  2. **Allow**: 크롤링을 허용할 경로입니다 (/ 부터의 상대 경로).
  3. **Disallow**: 크롤링을 제한할 경로입니다 (/ 부터의 상대 경로).
  4. **Sitemap**: 사이트맵이 위치한 경로의 전체 URL입니다 (https:// 부터 /sitemap.xml 까지의 전체 절대경로 URL). ([View Highlight](https://read.readwise.io/read/01hvn9cf97pcp6n33b50gvcgv7))
